{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\VSC_PROJECTS\\video_detection_moving_object\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# type: ignore\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import ultralytics\n",
    "import torch\n",
    "import torchvision\n",
    "import scipy\n",
    "import sklearn\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import intel_npu_acceleration_library as npu_lib\n",
    "#import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.config.list_physical_devices()\n",
    "#tf.test.is_gpu_available(cuda_only=True, min_cuda_compute_capability=None)\n",
    "tf.config.list_physical_devices()\n",
    "#tensorflow run to npu device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ObjectTracker:\n",
    "    '''\n",
    "    class ObjectTracker: use opencv to track objects in a video stream\n",
    "    @param:\n",
    "\n",
    "    @cap: VideoCapture object\n",
    "    '''\n",
    "    def __init__(self, cap: cv2.VideoCapture=None):\n",
    "        # TODO: Initialize tracker object\n",
    "        self.cap = cap\n",
    "    def preprocess_frame(self):\n",
    "        # TODO: Implement preprocessing logic\n",
    "        return NotImplemented\n",
    "    def detect_object(self):\n",
    "        # TODO: Implement object detection logic\n",
    "        return NotImplemented\n",
    "    def track_object(self):\n",
    "        # TODO: Implement object tracking logic\n",
    "        return NotImplemented\n",
    "    def accuracy_check(self):\n",
    "        # TODO: Implement accuracy check logic\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create #time_decorator\n",
    "import time\n",
    "def time_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time: {execution_time} seconds\")\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo tracking Objects in Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#idea1\n",
    "s - часть изображения которая уже аналтизирована\n",
    "v - часть изображения которая еще не аналтизирована\n",
    "ROI для s это\n",
    "- новые аномалии\n",
    "- определенные объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectTrackerHOG(ObjectTracker):\n",
    "    def detect_object(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return    \n",
    "        hog = cv2.HOGDescriptor()\n",
    "        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "        found_rects, found_weights = hog.detectMultiScale(frame, winStride=(4, 4), scale=1.02)\n",
    "        #found_rects show\n",
    "        r = []\n",
    "        for i, (x, y, w, h) in enumerate(found_rects):\n",
    "            r.append(cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2))\n",
    "        #plt show rectangle\n",
    "        #plt.imshow(r)\n",
    "        plt.show()\n",
    "        #cv2.imshow(\"frame\", frame)\n",
    "        self.cap.release()\n",
    "class ObjectTrackerYOLO11(ObjectTracker):\n",
    "    @time_decorator\n",
    "    def detect_object(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "        yolo11 = ultralytics.YOLO(\"yolo11n.pt\")\n",
    "        cv2.GaussianBlur(frame, (5, 5), 0, frame)\n",
    "        res  = yolo11(frame)\n",
    "        plt.imshow(res[0].plot())\n",
    "        plt.show()\n",
    "        #cv2.imshow(\"frame\", frame)\n",
    "        self.cap.release()\n",
    "\n",
    "try:\n",
    "    cm = cv2.VideoCapture(0)\n",
    "    track = ObjectTrackerHOG(cm).detect_object()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    cm.release()\n",
    "finally:\n",
    "    cm.release()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
